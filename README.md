# AIMEæ•°æ®é›†ç”Ÿæˆç³»ç»Ÿ

åŸºäºCAMELæ¡†æ¶çš„å®Œæ•´AIMEé£æ ¼æ•°å­¦é¢˜ç›®ç”ŸæˆPipelineï¼ŒåŒ…å«æ•°æ®ç”Ÿæˆã€äººå·¥éªŒè¯å’Œè´¨é‡è¯„ä¼°ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®API Key

**æ–¹æ³•1: ç¯å¢ƒå˜é‡**
```bash
# Windows PowerShell
$env:OPENAI_API_KEY="your-api-key"

# Linux/Mac
export OPENAI_API_KEY="your-api-key"
```

**æ–¹æ³•2: ä¿®æ”¹config.py**
```python
OPENAI_API_KEY = "your-api-key"
```

### 3. ç”Ÿæˆæ•°æ®

```bash
# ç”Ÿæˆ10ä¸ªAIMEé¢˜ç›®
python run_full_pipeline.py --num_problems 10

# å¿«é€Ÿæµ‹è¯•ï¼ˆ2ä¸ªé¢˜ç›®ï¼‰
python test_stages.py --all
```

### 4. äººå·¥éªŒè¯

```bash
# å¯åŠ¨WebéªŒè¯ç•Œé¢
python verification_ui.py

# æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://127.0.0.1:7860
```

### 5. è´¨é‡è¯„ä¼°

```bash
# è‡ªåŠ¨ç”ŸæˆæŒ‡æ ‡ã€å›¾è¡¨å’ŒæŠ¥å‘Š
python run_evaluation.py
```

---

## ğŸ“Š å®Œæ•´å·¥ä½œæµç¨‹

```
ç¬¬1æ­¥: æ•°æ®ç”Ÿæˆï¼ˆè‡ªåŠ¨åŒ–ï¼‰
  python run_full_pipeline.py --num_problems 10
  â†“
  è¾“å‡º: output/stage4_improved/improved_problems.json

ç¬¬2æ­¥: äººå·¥éªŒè¯ï¼ˆå¯é€‰ï¼‰
  python verification_ui.py
  â†“
  è¾“å‡º: verification/verified_problems/verifications.json

ç¬¬3æ­¥: è´¨é‡è¯„ä¼°ï¼ˆè‡ªåŠ¨åŒ–ï¼‰
  python run_evaluation.py
  â†“
  è¾“å‡º: 
    - evaluation/quality_metrics.json
    - evaluation/figures/*.png (7å¼ å›¾è¡¨)
    - evaluation/reports/experiment_report.md

ç¬¬4æ­¥: éªŒè¯ç»“æœåˆ†æï¼ˆå¯é€‰ï¼‰
  python analyze_verification.py
  â†“
  è¾“å‡º: éªŒè¯ç»Ÿè®¡æŠ¥å‘Šå’Œå›¾è¡¨
```

è¯¦ç»†æµç¨‹è¯·æŸ¥çœ‹: [WORKFLOW.md](WORKFLOW.md)

---

## ğŸ¯ æ ¸å¿ƒè„šæœ¬

| è„šæœ¬ | åŠŸèƒ½ | è¾“å‡º |
|------|------|------|
| `run_full_pipeline.py` | 4é˜¶æ®µæ•°æ®ç”Ÿæˆ | `improved_problems.json` |
| `test_stages.py` | æµ‹è¯•å„é˜¶æ®µ | æµ‹è¯•è¾“å‡º |
| `verification_ui.py` | äººå·¥éªŒè¯Webç•Œé¢ | `verifications.json` |
| `analyze_verification.py` | éªŒè¯ç»“æœåˆ†æ | éªŒè¯æŠ¥å‘Š+å›¾è¡¨ |
| `run_evaluation.py` | è´¨é‡è¯„ä¼° | æŒ‡æ ‡+å›¾è¡¨+æŠ¥å‘Š |

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
aime_datagen_experiment/
â”œâ”€â”€ README.md                    # æœ¬æ–‡ä»¶
â”œâ”€â”€ WORKFLOW.md                  # è¯¦ç»†å·¥ä½œæµç¨‹
â”œâ”€â”€ config.py                    # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt             # ä¾èµ–
â”‚
â”œâ”€â”€ run_full_pipeline.py         # ä¸»è¦æ•°æ®ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ test_stages.py               # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ verification_ui.py           # äººå·¥éªŒè¯UI
â”œâ”€â”€ analyze_verification.py      # éªŒè¯åˆ†æ
â”œâ”€â”€ run_evaluation.py            # è´¨é‡è¯„ä¼°
â”œâ”€â”€ start_verification.bat       # Windowså¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ src/                         # æºä»£ç 
â”‚   â”œâ”€â”€ problem_generator.py     # Stage 1: ChatAgent
â”‚   â”œâ”€â”€ diversifier.py           # Stage 2: Self-Instruct
â”‚   â”œâ”€â”€ solution_generator.py    # Stage 3: CoTDataGenerator
â”‚   â””â”€â”€ quality_improver.py      # Stage 4: SelfImprovingCoTPipeline
â”‚
â”œâ”€â”€ evaluation/                  # è¯„ä¼°å·¥å…·
â”‚   â”œâ”€â”€ quality_metrics.py       # è´¨é‡æŒ‡æ ‡è®¡ç®—
â”‚   â”œâ”€â”€ visualize_results.py     # å¯è§†åŒ–å›¾è¡¨
â”‚   â”œâ”€â”€ generate_report.py       # æŠ¥å‘Šç”Ÿæˆ
â”‚   â”œâ”€â”€ quality_metrics.json     # æŒ‡æ ‡æ•°æ®
â”‚   â”œâ”€â”€ figures/                 # ç”Ÿæˆçš„å›¾è¡¨
â”‚   â””â”€â”€ reports/                 # ç”Ÿæˆçš„æŠ¥å‘Š
â”‚
â”œâ”€â”€ verification/                # éªŒè¯ç³»ç»Ÿ
â”‚   â”œâ”€â”€ verified_problems/       # éªŒè¯ç»“æœ
â”‚   â””â”€â”€ (å›¾è¡¨å’ŒæŠ¥å‘Š)
â”‚
â””â”€â”€ output/                      # ç”Ÿæˆçš„æ•°æ®
    â”œâ”€â”€ stage1_base_problems/
    â”œâ”€â”€ stage2_diversified/
    â”œâ”€â”€ stage3_with_solutions/
    â””â”€â”€ stage4_improved/         # æœ€ç»ˆè¾“å‡º
```

---

## ğŸ”¬ Pipelineæ¶æ„

### 4é˜¶æ®µæ•°æ®ç”Ÿæˆ

```
Stage 1: ChatAgent
  â†“ ç”ŸæˆåŸºç¡€AIMEé¢˜ç›®
Stage 2: Self-Instruct
  â†“ é¢˜ç›®å¤šæ ·åŒ–ï¼ˆå¸¦Fallbackæœºåˆ¶ï¼‰
Stage 3: CoTDataGenerator
  â†“ MCTSæœç´¢ç”Ÿæˆè§£ç­”
Stage 4: SelfImprovingCoTPipeline
  â†“ STaRè¿­ä»£æ”¹è¿›è´¨é‡
Final: é«˜è´¨é‡AIMEæ•°æ®é›†
```

### æŠ€æœ¯ç»†èŠ‚

| æ¨¡å— | æŠ€æœ¯ | é…ç½® |
|------|------|------|
| Stage 1 | ChatAgent | GPT-4o, AIME prompt |
| Stage 2 | Self-Instruct | ROUGE filtering + Fallback |
| Stage 3 | CoTDataGenerator | MCTS (50 iterations) |
| Stage 4 | SelfImprovingCoTPipeline | STaR (2-3 iterations) |

---

## ğŸ¨ äººå·¥éªŒè¯æŒ‡å—

### å¯åŠ¨éªŒè¯UI

```bash
python verification_ui.py
# æˆ–åŒå‡»: start_verification.bat
```

### éªŒè¯æµç¨‹

1. **é˜…è¯»é¢˜ç›®**: é—®é¢˜ã€ç­”æ¡ˆã€è§£ç­”
2. **è¯„åˆ†** (1-5åˆ†):
   - æ­£ç¡®æ€§ (Correctness)
   - æ¸…æ™°åº¦ (Clarity)
   - éš¾åº¦åŒ¹é… (Difficulty Match)
   - å®Œæ•´æ€§ (Completeness)
3. **æ ‡æ³¨çŠ¶æ€**:
   - âœ… approved (é€šè¿‡)
   - âŒ rejected (æ‹’ç»)
   - ğŸ”„ needs_revision (éœ€ä¿®æ”¹)
4. **æ·»åŠ è¯„è®º**: å…·ä½“åé¦ˆ

### éªŒè¯æ ‡å‡†

**é€šè¿‡æ ‡å‡† (approved)**:
- æ•°å­¦å®Œå…¨æ­£ç¡®
- è§£ç­”æ¸…æ™°å®Œæ•´
- éš¾åº¦é€‚ä¸­ï¼ˆ6-9/15ï¼‰
- æ ¼å¼è§„èŒƒ

**æ‹’ç»æ ‡å‡† (rejected)**:
- æ•°å­¦é”™è¯¯ä¸¥é‡
- ç­”æ¡ˆé”™è¯¯
- éš¾åº¦ä¸¥é‡ä¸åŒ¹é…

**éœ€ä¿®æ”¹ (needs_revision)**:
- æœ‰å°çš„æ•°å­¦é”™è¯¯ï¼ˆå¯ä¿®æ­£ï¼‰
- è§£ç­”ä¸å¤Ÿå®Œæ•´ï¼ˆå¯è¡¥å……ï¼‰
- æ ¼å¼æœ‰é—®é¢˜ï¼ˆå¯è°ƒæ•´ï¼‰

---

## ğŸ“Š è´¨é‡è¯„ä¼°

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | ç›®æ ‡å€¼ |
|---------|---------|--------|
| **å¤šæ ·æ€§** | å¤šæ ·æ€§åˆ†æ•° | > 0.7 |
| **éš¾åº¦** | AIMEèŒƒå›´åŒ¹é…ç‡ | > 80% |
| **ä¸»é¢˜** | ä¸»é¢˜å‡è¡¡åº¦ | > 0.8 |
| **è§£ç­”** | å®Œæ•´æ€§ | > 95% |

### ç”Ÿæˆçš„å›¾è¡¨

1. `difficulty_distribution.png` - éš¾åº¦åˆ†å¸ƒç›´æ–¹å›¾
2. `topic_distribution.png` - ä¸»é¢˜åˆ†å¸ƒé¥¼å›¾
3. `answer_distribution.png` - ç­”æ¡ˆåˆ†å¸ƒç›´æ–¹å›¾
4. `solution_steps_distribution.png` - è§£ç­”æ­¥éª¤åˆ†å¸ƒ
5. `quality_radar.png` - è´¨é‡é›·è¾¾å›¾
6. `stage_comparison.png` - Pipelineé˜¶æ®µå¯¹æ¯”
7. `tag_frequency.png` - æ ‡ç­¾é¢‘ç‡å›¾

### è¯„ä¼°æŠ¥å‘Š

è¿è¡Œ`python run_evaluation.py`åç”Ÿæˆï¼š
- `evaluation/quality_metrics.json` - è´¨é‡æŒ‡æ ‡æ•°æ®
- `evaluation/figures/*.png` - 7å¼ å¯è§†åŒ–å›¾è¡¨
- `evaluation/reports/experiment_report.md` - å®Œæ•´å®éªŒæŠ¥å‘Š

---

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: å¿«é€Ÿæµ‹è¯•

```bash
python test_stages.py --all
python run_evaluation.py
```

### åœºæ™¯2: ç”Ÿæˆè®ºæ–‡æ•°æ®

```bash
python run_full_pipeline.py --num_problems 50
python verification_ui.py  # äººå·¥éªŒè¯
python run_evaluation.py   # ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨
python analyze_verification.py
```

### åœºæ™¯3: åªçœ‹è‡ªåŠ¨è¯„ä¼°

```bash
python run_full_pipeline.py --num_problems 10
python run_evaluation.py  # è·³è¿‡äººå·¥éªŒè¯
```

---

## ğŸ”§ é…ç½®è¯´æ˜

### ä¸»è¦é…ç½®é¡¹ (config.py)

```python
# APIé…ç½®
OPENAI_API_KEY = "your-key"
MODEL_TYPE = ModelType.GPT_4O  # æˆ– GPT_4O_MINI

# Stage 1: åŸºç¡€é¢˜ç›®ç”Ÿæˆ
STAGE1_NUM_PROBLEMS = 2

# Stage 2: å¤šæ ·åŒ–
STAGE2_DIVERSIFICATION_FACTOR = 2

# Stage 3: MCTSè§£ç­”ç”Ÿæˆ
STAGE3_NUM_SEARCH = 50

# Stage 4: STaRæ”¹è¿›
STAGE4_MAX_ITERATIONS = 2
```

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- [WORKFLOW.md](WORKFLOW.md) - å®Œæ•´å·¥ä½œæµç¨‹è¯¦è§£ï¼ˆæ¨èé˜…è¯»ï¼‰

---

## ğŸ¯ æ ¸å¿ƒç†è§£

### æ•°æ®æµå‘

```
CAMELç”Ÿæˆ â†’ improved_problems.json
              â†“
         äººå·¥éªŒè¯ â†’ verifications.json (å¯é€‰)
              â†“
         è´¨é‡è¯„ä¼° â†’ metrics + å›¾è¡¨ + æŠ¥å‘Š
```

### ä¸¤ç§è¯„ä¼°æ¨¡å¼

**æ¨¡å¼1: è‡ªåŠ¨è¯„ä¼°ï¼ˆæ— äººå·¥æ ‡æ³¨ï¼‰**
- åŸºäºç”Ÿæˆæ•°æ®æœ¬èº«
- è¯„ä¼°å¤šæ ·æ€§ã€éš¾åº¦ã€ä¸»é¢˜ç­‰
- é€‚åˆå¿«é€Ÿè¿­ä»£

**æ¨¡å¼2: å®Œæ•´è¯„ä¼°ï¼ˆå«äººå·¥æ ‡æ³¨ï¼‰**
- åŸºäºç”Ÿæˆæ•°æ® + äººå·¥éªŒè¯
- è¯„ä¼°æ‰€æœ‰æŒ‡æ ‡ + äººå·¥è¯„åˆ†
- é€‚åˆè®ºæ–‡å‘è¡¨

---

## ğŸ“ è·å–å¸®åŠ©

- æŸ¥çœ‹è¯¦ç»†æµç¨‹: `cat WORKFLOW.md`
- æŸ¥çœ‹é…ç½®: `cat config.py`
- æŸ¥çœ‹ä¾èµ–: `cat requirements.txt`

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. é…ç½®API Key
# ç¼–è¾‘ config.py

# 3. ç”Ÿæˆæ•°æ®
python run_full_pipeline.py --num_problems 10

# 4. äººå·¥éªŒè¯
python verification_ui.py

# 5. è´¨é‡è¯„ä¼°
python run_evaluation.py
```


